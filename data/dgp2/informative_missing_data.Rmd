---
title: "Informative Missing Data"
author: "Amos Okutse"
date: "  `r format(Sys.time(), '%d %B, %Y')` "
header-includes:
- \usepackage{color, colortbl}  % for using table colors
- \definecolor{Gray}{gray}{0.9}  %define the color to be used
- \usepackage{multirow}
- \usepackage{pdflscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
- \usepackage{fvextra}
- \usepackage{float}
- \usepackage{wrapfig}
- \usepackage{amsmath}
- \usepackage{float}
- \usepackage{graphicx}
- \usepackage{microtype}
- \usepackage{setspace}
- \usepackage[font=singlespacing]{caption} #can change font here for captions here!!
- \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines, commandchars=\\\{\}}
fontsize: 10pt
output:
  bookdown::pdf_document2:
    latex_engine: xelatex
    toc: true
    toc_depth: 4
    number_sections: true
link-citation: yes
colorlinks: yes
linkcolor: blue
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	cache = FALSE,
	message = FALSE,
	warning = FALSE,
	fig.align = 'center',
	fig.pos = 'H',
	dpi = 350,
	tidy.opts = list(width.cutoff = 80, tidy = TRUE)
)
```

```{r, echo=FALSE, include= FALSE}
# function to install missing packages
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE, repos='http://cran.rstudio.com/')
  sapply(pkg, require, character.only = TRUE)
}
packages =c( "tidyverse","knitr", "kableExtra","skimr", "MatchIt", "RItools","optmatch", "ggplot2", "tufte", "tufterhandout", "plotly", "snowfall", "rstan", "gridExtra", "knitr", "gtsummary", "data.table", "GGally", "MASS", "broom", "boot", "foreach", "doParallel", "glmnet", "tidymodels" , "usemodels", "magrittr", "modelr")
ipak(packages)
```

## Introduction

- This data generation mechanism examines a more informative missing data mechanism and specifically, the role of covariate adjustment when the missing data is not only dependent on the adjustment covariates in a misspecified model but also on the treatment variable, and the effect modification of the treatment effect by a single adjustment covariate. 

- We explore the effect of the omission of the treatment effect modifying covariate on the subsequent treatment effect estimates as well as missing data-induced bias when the adjustment covariates are fair to highly prognostic of the outcome under correct and incorrect model misspecifications. 

- The outcome data generation mechanism is specified as $y = 210 + 50*A + \theta_1 * A*Z_1 + 27.4*Z_1 + 13.7*Z_2 + 13.7*Z_3 + 13.7*Z_4 + e$ whereas the missing data model is $R = \textrm{expit}(-Z_1 + \eta_0*A + \eta_1*A*Z_1 +0.5*Z_2 - 0.25*Z_3 - 0.1*Z_4)$. We generate the actual adjustment covariates under incorrect model specification as $x_1 = exp(Z_1/2),\: x_2 = Z_2/(1+exp(Z_1))+10, \: x_3 = (Z_1Z_3/25 + 0.6)^3,\: x_4 = (Z_2 + Z_4 + 20)^2$ assuming that these are the variables the analyst has access to.

## Simulation settings

- **Simulation setting 1** is a correctly specified model synonymous with the previous analysis scenarios where the adjustment model is linear and the adjustment covariates are the true outcome generating variables specified in the outcome model.

(1) [Model 1] Given $\theta_1 = \eta_0 = \eta_1 = 0$ including $Z_1, \cdots, Z_4$ in adjustment model 1 is not supposed to result in substantial bias (no bias since we are adjusting for the true y generating covariates; also maximum precision when sd = 1 compared to sd = 45)

(2) [Model 2] Dropping $Z_1$ in the adjustment model should result in a model misspecification which will not have a substantial effect given the above conditions do not induce a dependence of the $R$ and $y$ models on $Z_1$

- **Simulation setting 2** has the conditions $\theta_1 = \eta_1 = 0$ whereas $\eta_0 = 1$. This setting induces a dependence of the missing data mechanism on the treatment variable, $A$. 

(1) [Model 1] Including all the Z's in the adjustment model should not result in substantial biases (if any). 

(2) [Model 2] Dropping the $Z$ in the adjustment model should result in some bias (higher bias compared to Model 1 given that adjustment does not consider treatment effect modification by the cvariate $Z_1$)

- **Simulation setting 3** has the conditions $\theta_1 = 0, \: \eta_0 = 1, \: \eta_1 = -1$ alluding to the dependence of the missing data mechanism on the treatment, $A$ and the potential effect modification by variable $Z_1$.

(1) [Model 1] should expect to see limited bias if any since the adjustment is for true outcome-generating variables.

(2) [Model 2] should expect to see bias higher when residual sd is high since we do not consider the effect modification by $Z_1$ in the adjustment when we drop this variable from the adjustment model. 

- When we adjust for a variable on which the missing data mechanism depends, we should expect to see some gains in precision and reductions in bias. Gains should be higher when the proportion of variance explained by the adjustment covariates is higher.

## Data generation mechanisms

```{r}
## set the working directory
# setwd("/Users/aokutse/Library/CloudStorage/GoogleDrive-amos_okutse@brown.edu/Shared drives/amos/ThesisResults/data/dgp2")
```

```{r echo=TRUE}
## data generation function for all simulation settings
## the saved data file should contain both the Z and the X for adjustment under correct and incorrect model specifications. 
## the linear model adjusting for the Z's is the correctly specified model and the efficiency gains given this model represent the optimal expected gains. [no misspecified model should outperform this model]
set.seed(123)
dgp2 <- function(n, ss, theta, eta0, eta1) {
  #' theta is the modifying effect of Z_1 on the treatment, A
  #' eta0 is the effect of A on the missing data mechanism
  #' ss is the residual standard deviation on the true outcome model
  #' n is the desired sample size
  #' eta1 is the effect modification of Z_1 on A in the missing data model

  # treatment variable
  A <- c()
  for (i in 1:n){if (i <= n/2){ A[i] = 1} else {if (i > n/2){A[i] = 0}}}
  # create the dataframe with the true covariates
  mat <- data.frame(
    z1 <- rnorm(n = n, mean = 0, sd = 1), 
    z2 <- rnorm(n = n, mean = 0, sd = 1),
    z3 <- rnorm(n = n, mean = 0, sd = 1), 
    z4 <- rnorm(n = n, mean = 0, sd = 1))
  colnames(mat) <- c("z1", "z2", "z3", "z4")
  # generate the error term
  e <- rnorm(n = n, mean = 0, sd = ss)
  # generate the outcome variable based on the specified model
  y <- 210 + 50*A + theta*A*mat[, 1] + 27.4*mat[ ,1] + 13.7*mat[, 2] + 13.7*mat[, 3] + 13.7*mat[, 4] + e
  # generate the xi's actually observed by analyst
  x1 <- exp(mat[, 1]/2); x2 <- (mat[, 2]/ (1 + exp(mat[, 1]))) + 10; x3 <- (((mat[, 1]*mat[, 3])/25) + 0.6)^3; x4 <- (mat[,2] + mat[,4] + 20)^2
  # create the missing data variable based on the treatment
  pi <- locfit::expit(0 - mat[, 1] + eta0*A + eta1*A*mat[, 1] + 0.5*mat[, 2] - 0.25*mat[, 3] - 0.1*mat[, 4])
  R = rbinom(n = n, size = 1, prob = pi)
  # save variables as a data frame
  df <-data.frame(y, A, x1, x2, x3, x4, R, e, mat)
} 
```

### Setting One Datasets

- Data sets for simulation setting 1

Each dataset here will be modeled under two scenarios where there's adjustment for all covariates and where there is adjustment excluding the covariate on which the missing data pattern depends on.

```{r eval=FALSE, echo=TRUE}
set.seed(123)
# The organization of the files for each simulation setting hold as below
#sd = 1; n = 500
s_onea <- dgp2(n = 500, ss = 1, theta = 0, eta0 = 0, eta1 = 0)
# sd = 45; n = 500
s_oneb <- dgp2(n = 500, ss = 45, theta = 0, eta0 = 0, eta1 = 0)
# sd = 1; n = 2000
s_onec <- dgp2(n = 2000, ss = 1, theta = 0, eta0 = 0, eta1 = 0)
# sd = 45; n = 2000
s_oned <- dgp2(n = 2000, ss = 45, theta = 0, eta0 = 0, eta1 = 0)

## 1000 simulated datasets saved as a list
cores <- parallel::detectCores()
doParallel::registerDoParallel(cores - 1)
s1a = foreach(1:1000) %dopar% dgp2(n = 500, ss = 1, theta = 0, eta0 = 0, eta1 = 0)
s1b = foreach(1:1000) %dopar% dgp2(n = 500, ss = 45, theta = 0, eta0 = 0, eta1 = 0)
s1c = foreach(1:1000) %dopar% dgp2(n = 2000, ss = 1, theta = 0, eta0 = 0, eta1 = 0)
s1d = foreach(1:1000) %dopar% dgp2(n = 2000, ss = 45, theta = 0, eta0 = 0, eta1 = 0)

## Save all data sets as one for analyses under simulation setting one (one.RData)
# save("s_onea", "s_oneb", "s_onec", "s_oned", "s1a", "s1b", "s1c", "s1d", file = "/Users/aokutse/Library/CloudStorage/GoogleDrive-amos_okutse@brown.edu/Shared drives/amos/ThesisResults/data/dgp2/one.RData")
```

### Setting Two Datasets

- Datasets for simulation setting 2

```{r eval=FALSE, echo=TRUE}
set.seed(123)
#sd = 1; n = 500
s_twoa <- dgp2(n = 500, ss = 1, theta = 0, eta0 = 1, eta1 = 0)
# sd = 45; n = 500
s_twob <- dgp2(n = 500, ss = 45, theta = 0, eta0 = 1, eta1 = 0)
# sd = 1; n = 2000
s_twoc <- dgp2(n = 2000, ss = 1, theta = 0, eta0 = 1, eta1 = 0)
# sd = 45; n = 2000
s_twod <- dgp2(n = 2000, ss = 45, theta = 0, eta0 = 1, eta1 = 0)


## Simulate 1000 data sets and save them as a list for further analysis
cores <- parallel::detectCores()
doParallel::registerDoParallel(cores - 1)
s2a = foreach(1:1000) %dopar% dgp2(n = 500, ss = 1, theta = 0, eta0 = 1, eta1 = 0)
s2b = foreach(1:1000) %dopar% dgp2(n = 500, ss = 45, theta = 0, eta0 = 1, eta1 = 0)
s2c = foreach(1:1000) %dopar% dgp2(n = 2000, ss = 1, theta = 0, eta0 = 1, eta1 = 0)
s2d = foreach(1:1000) %dopar% dgp2(n = 2000, ss = 45, theta = 0, eta0 = 1, eta1 = 0)

## save all data sets as one for analyses under simulation setting two data (two.RData)
# save("s_twoa", "s_twob", "s_twoc", "s_twod", "s2a", "s2b", "s2c", "s2d", file = "/Users/aokutse/Library/CloudStorage/GoogleDrive-amos_okutse@brown.edu/Shared drives/amos/ThesisResults/data/dgp2/two.RData")
```

### Setting Three Datasets

- Datasets for simulation setting 3

```{r eval=FALSE, echo=TRUE}
set.seed(123)
## datasets for simulation setting three
#sd = 1; n = 500
s_threea <- dgp2(n = 500, ss = 1, theta = 0, eta0 = 1, eta1 = 1)
# sd = 45; n = 500
s_threeb <- dgp2(n = 500, ss = 45, theta = 0, eta0 = 1, eta1 = 1)
# sd = 1; n = 2000
s_threec <- dgp2(n = 2000, ss = 1, theta = 0, eta0 = 1, eta1 = 1)
# sd = 45; n = 2000
s_threed <- dgp2(n = 2000, ss = 45, theta = 0, eta0 = 1, eta1 = 1)


## Simulate 1000 data sets and save them as a list for further analysis
cores <- parallel::detectCores()
doParallel::registerDoParallel(cores - 1)
s3a = foreach(1:1000) %dopar% dgp2(n = 500, ss = 1, theta = 0, eta0 = 1, eta1 = 1)
s3b = foreach(1:1000) %dopar% dgp2(n = 500, ss = 45, theta = 0, eta0 = 1, eta1 = 1)
s3c = foreach(1:1000) %dopar% dgp2(n = 2000, ss = 1, theta = 0, eta0 = 1, eta1 = 1)
s3d = foreach(1:1000) %dopar% dgp2(n = 2000, ss = 45, theta = 0, eta0 = 1, eta1 = 1)

## Save all data sets as one for analyses corresponding to simulation setting three data (one.RData)
 save("s_threea", "s_threeb", "s_threec", "s_threed", "s3a", "s3b", "s3c", "s3d", file = "/Users/aokutse/Library/CloudStorage/GoogleDrive-amos_okutse@brown.edu/Shared drives/amos/ThesisResults/data/dgp2/three.RData")
```

