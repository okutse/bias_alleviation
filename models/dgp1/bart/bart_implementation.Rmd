---
title: "Untuned Bayesian Additive Regression Trees (BART)"
author: "Amos Okutse"
date: "  `r format(Sys.time(), '%d %B, %Y')` "
header-includes:
- \usepackage{color, colortbl}  % for using table colors
- \definecolor{Gray}{gray}{0.9}  %define the color to be used
- \usepackage{multirow}
- \usepackage{pdflscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}
- \usepackage{fvextra}
- \usepackage{float}
- \usepackage{wrapfig}
- \usepackage{amsmath}
- \usepackage{float}
- \usepackage{graphicx}
- \usepackage{microtype}
- \usepackage{setspace}
- \usepackage[font=singlespacing]{caption} #can change font here for captions here!!
- \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines, commandchars=\\\{\}}
#- \onehalfspacing
fontsize: 10pt
output:
  bookdown::pdf_document2:
    latex_engine: xelatex
    toc: true
    toc_depth: 4
    number_sections: true
    keep_md: false
link-citation: yes
colorlinks: yes
linkcolor: blue
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	cache = FALSE,
	message = FALSE,
	warning = FALSE,
	fig.align = 'center',
	fig.pos = 'H',
	dpi = 350,
	tidy.opts = list(width.cutoff = 80, tidy = TRUE)
)
```

```{r, echo=FALSE, include= FALSE}
# function to install missing packages
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE, repos='http://cran.rstudio.com/')
  sapply(pkg, require, character.only = TRUE)
}
packages =c( "tidyverse","knitr", "kableExtra","skimr", "MatchIt", "RItools","optmatch", "ggplot2", "tufte", "tufterhandout", "plotly", "snowfall", "rstan", "gridExtra", "knitr", "gtsummary", "data.table", "GGally", "MASS", "broom", "boot", "foreach", "doParallel", "glmnet", "tidymodels" , "usemodels", "magrittr")
ipak(packages)
```


```{r}
rm(list = ls())
## load the saved single data files
## load the individual data files
load("G:\\Shared drives\\amos\\ThesisResults\\data\\df_one.RData")
load("G:\\Shared drives\\amos\\ThesisResults\\data\\df_two.RData")
load("G:\\Shared drives\\amos\\ThesisResults\\data\\df_three.RData")
load("G:\\Shared drives\\amos\\ThesisResults\\data\\df_four.RData")

## load the saved list data files
load("G:\\Shared drives\\amos\\ThesisResults\\data\\dsets1.RData")
load("G:\\Shared drives\\amos\\ThesisResults\\data\\dsets2.RData")
load("G:\\Shared drives\\amos\\ThesisResults\\data\\dsets3.RData")
load("G:\\Shared drives\\amos\\ThesisResults\\data\\dsets4.RData")
```


- The Discrete Bayesian Additive Regression Tree Sample (`dbarts`) package is used for all BART models. `dbarts` relies on the `BayesTree` package as its BART engine and allows updating of the BART model with new predictors and response values to incorporate into a larger Bayesian model.

- The model has 4 tuning parameters including:

(i) the number of trees 
(ii) the terminal node prior coefficient
(iii) the terminal node prior exponent, and
(iv) and the prior for the outcome range.
## SECTION A
## FULL DATA

```{r}

bart_one <- function(df = NULL){
  # fit random forest model for all individuals
  bart_all <- parsnip::bart(
    mode = "regression") %>%
    set_engine("dbarts") %>% 
  fit(formula = y ~ A + x1 + x2 + x3 + x4, data = df)
## set A = 0 and generate predictions for everyone
  df_A0 <- df
  df_A0$A <- 0
  pred_A0 <- predict(bart_all, df_A0)
## set A = 1 and generate predictions for everyone
  df_A1 <- df
  df_A1$A <- 1
  pred_A1 <- predict(bart_all, df_A1)
## compute the ATE
  ATE_adjusted = mean(pred_A1$.pred - pred_A0$.pred)
## compute the bias
  bias_adjusted = ATE_adjusted - 50
## return the results as a data frame
  rslt = data.frame("ATE_adjusted" = ATE_adjusted, "bias_adjusted" = bias_adjusted)
  return(rslt)
}
```


```{r cache=TRUE, include=FALSE}
cores <- detectCores()-1
registerDoParallel(cores)
cl=makeCluster(cores)
clusterEvalQ(cl, c(library(tidyverse), library(tidymodels), library(magrittr), set.seed(123)))
## compute the estimates of the average treatment effect for each data set
  onea = parLapply(cl, dsets1, bart_one)
  oneb = parLapply(cl, dsets2, bart_one)
  onec = parLapply(cl, dsets3, bart_one)
  oned = parLapply(cl, dsets4, bart_one)
stopCluster(cl)
```


```{r}
# combine the results into a data frame
  onea <- onea %>% map_dfr(data.frame)
  oneb <- oneb %>% map_dfr(data.frame)
  onec <- onec %>% map_dfr(data.frame)
  oned <- oned %>% map_dfr(data.frame)
```


## OBSERVED DATA

```{r}

bart_two <- function(df = NULL){
  ## filter the data to have only individuals with R = 1
  df = dplyr::filter(df, R == 1)
  # fit random forest model for all individuals
  bart_two <- parsnip::bart(
    mode = "regression") %>%
    set_engine("dbarts") %>% 
  fit(formula = y ~ A + x1 + x2 + x3 + x4, data = df)
## set A = 0 and generate predictions for everyone
  df_A0 <- df
  df_A0$A <- 0
  pred_A0 <- predict(bart_two, df_A0)
## set A = 1 and generate predictions for everyone
  df_A1 <- df
  df_A1$A <- 1
  pred_A1 <- predict(bart_two, df_A1)
## compute the ATE
  ATE_adjusted = mean(pred_A1$.pred - pred_A0$.pred)
## compute the bias
  bias_adjusted = ATE_adjusted - 50
## return the results as a data frame
  rslt = data.frame("ATE_adjusted" = ATE_adjusted, "bias_adjusted" = bias_adjusted)
  return(rslt)
}
```


```{r cache=TRUE, include=FALSE}
cores <- detectCores()-1
registerDoParallel(cores)
cl=makeCluster(cores)
clusterEvalQ(cl, c(library(tidyverse), library(tidymodels), library(magrittr), set.seed(123)))
## compute the estimates of the average treatment effect for each data set
  twoa = parLapply(cl, dsets1, bart_two)
  twob = parLapply(cl, dsets2, bart_two)
  twoc = parLapply(cl, dsets3, bart_two)
  twod = parLapply(cl, dsets4, bart_two)
stopCluster(cl)
```


```{r}
# combine the results into a data frame
  twoa <- twoa %>% map_dfr(data.frame)
  twob <- twob %>% map_dfr(data.frame)
  twoc <- twoc %>% map_dfr(data.frame)
  twod <- twod %>% map_dfr(data.frame)
```


## OBSERVED MODIFIED

```{r}
## create the function to return the desired estimates from the model
bart_three <- function(df = NULL){
  # fit random forest model for all individuals with R=1
  bart_three <- parsnip::bart(
    mode = "regression") %>%
    set_engine("dbarts") %>% 
  fit(formula = y ~ A + x1 + x2 + x3 + x4, data = dplyr::filter(df, R == 1))
## set A = 0 and generate predictions for everyone
  df_A0 <- df
  df_A0$A <- 0
  pred_A0 <- predict(bart_three, df_A0)
## set A = 1 and generate predictions for everyone
  df_A1 <- df
  df_A1$A <- 1
  pred_A1 <- predict(bart_three, df_A1)
## compute the ATE
  ATE_adjusted = mean(pred_A1$.pred) - mean(pred_A0$.pred)
## compute the bias
  bias_adjusted = ATE_adjusted - 50
## return the results as a data frame
  rslt = data.frame("ATE_adjusted" = ATE_adjusted, "bias_adjusted" = bias_adjusted)
  return(rslt)
}
```


```{r cache=TRUE, include=FALSE}
cores <- detectCores()-1
registerDoParallel(cores)
cl = makeCluster(cores)
clusterEvalQ(cl, c(library(tidyverse), library(tidymodels), library(magrittr), set.seed(123)))

## compute the estimated results across 1000 data frames
  threea = parLapply(cl, dsets1, bart_three)
  threeb = parLapply(cl, dsets2, bart_three)
  threec = parLapply(cl, dsets3, bart_three)
  threed = parLapply(cl, dsets4, bart_three)
stopCluster(cl)
```


```{r}
# combine the results into a data frame
  threea <- threea %>% map_dfr(data.frame)
  threeb <- threeb %>% map_dfr(data.frame)
  threec <- threec %>% map_dfr(data.frame)
  threed <- threed %>% map_dfr(data.frame)
```



```{r}
##------------------------------------------------------------------------------
## case 1 [n = 500, sd = 1]
##------------------------------------------------------------------------------
## full
full <- c(n = nrow(df_one), ate = mean(onea$ATE_adjusted), sd = sd(onea$ATE_adjusted), bias = mean(onea$bias_adjusted), sd_bias = sd(onea$bias_adjusted))
full
## observed
obs <- c(n = nrow(subset(df_one, R == 1)), ate = mean(twoa$ATE_adjusted), sd = sd(twoa$ATE_adjusted), bias = mean(twoa$bias_adjusted), sd_bias = sd(twoa$bias_adjusted))
obs
## observed modified
obs_m <- c(n = nrow(subset(df_one, R == 1)), ate = mean(threea$ATE_adjusted), sd = sd(threea$ATE_adjusted), bias = mean(threea$bias_adjusted), sd_bias = sd(threea$bias_adjusted))
obs_m


##------------------------------------------------------------------------------
## case 2 [n = 500, sd = 68]
##------------------------------------------------------------------------------
full2 <- c(n = nrow(df_two), ate = mean(oneb$ATE_adjusted), sd = sd(oneb$ATE_adjusted), bias = mean(oneb$bias_adjusted), sd_bias = sd(oneb$bias_adjusted))
full2
## observed
obs2 <- c(n = nrow(subset(df_two, R == 1)), ate = mean(twob$ATE_adjusted), sd = sd(twob$ATE_adjusted), bias = mean(twob$bias_adjusted), sd_bias = sd(twob$bias_adjusted))
obs2
## observed modified
obs_m2 <- c(n = nrow(subset(df_two, R == 1)), ate = mean(threeb$ATE_adjusted), sd = sd(threeb$ATE_adjusted), bias = mean(threeb$bias_adjusted), sd_bias = sd(threeb$bias_adjusted))
obs_m2


##------------------------------------------------------------------------------
## case 3 [n = 2000, sd = 1]
##------------------------------------------------------------------------------
full3 <- c(n = nrow(df_three), ate = mean(onec$ATE_adjusted), sd = sd(onec$ATE_adjusted), bias = mean(onec$bias_adjusted), sd_bias = sd(onec$bias_adjusted))
full3
## observed
obs3 <- c(n = nrow(subset(df_three, R == 1)), ate = mean(twoc$ATE_adjusted), sd = sd(twoc$ATE_adjusted), bias = mean(twoc$bias_adjusted), sd_bias = sd(twoc$bias_adjusted))
obs3
## observed modified
obs_m3 <- c(n = nrow(subset(df_three, R == 1)), ate = mean(threec$ATE_adjusted), sd = sd(threec$ATE_adjusted), bias = mean(threec$bias_adjusted), sd_bias = sd(threec$bias_adjusted))
obs_m3

##------------------------------------------------------------------------------
## case 4 [n = 2000, sd = 68]
##------------------------------------------------------------------------------
full4 <- c(n = nrow(df_four), ate = mean(oned$ATE_adjusted), sd = sd(oned$ATE_adjusted), bias = mean(oned$bias_adjusted), sd_bias = sd(oned$bias_adjusted))
full4
## observed
obs4 <- c(n = nrow(subset(df_four, R == 1)), ate = mean(twod$ATE_adjusted), sd = sd(twod$ATE_adjusted), bias = mean(twod$bias_adjusted), sd_bias = sd(twod$bias_adjusted))
obs4
## observed modified
obs_m4 <- c(n = nrow(subset(df_four, R == 1)), ate = mean(threed$ATE_adjusted), sd = sd(threed$ATE_adjusted), bias = mean(threed$bias_adjusted), sd_bias = sd(threed$bias_adjusted))
obs_m4
```

## TABLE OF BART RESULTS

```{r random-forest}
untuned_bart <- bind_rows(list("n = 500, SD = 1" = full, "n = 500, SD = 1" = obs, "n = 500, SD = 1"= obs_m, 
                               "n = 500, SD = 68" = full2, "n = 500, SD = 68" = obs2, "n = 500, SD = 68" = obs_m2,
                               "n = 2000, SD = 1" = full3, "n = 2000, SD = 1" = obs3, "n = 2000, SD = 1" = obs_m3, 
                               "n = 2000, SD = 68" = full4, "n = 2000, SD = 68"=  obs4, "n = 2000, SD = 68" = obs_m4),
                          .id = "Data generating values") 
kable(untuned_bart, format = "latex", caption = "BART results averaged across n = 1000 datasets under full, observed, and observed modified analysis")

## the order of the rows starts with n = 500 
write.csv(untuned_bart, file = "G:\\Shared drives\\amos\\ThesisResults\\[7]_bart\\untuned_bart.csv", row.names = FALSE)
```

## SECTION B

### FUNCTIONS

```{r}
##load all the data sets for this new simulations
rm(list = ls())

load("/Users/aokutse/Library/CloudStorage/GoogleDrive-amos_okutse@brown.edu/Shared drives/amos/ThesisResults/data/df_one.RData")
load("/Users/aokutse/Library/CloudStorage/GoogleDrive-amos_okutse@brown.edu/Shared drives/amos/ThesisResults/data/df_two.RData")
load("/Users/aokutse/Library/CloudStorage/GoogleDrive-amos_okutse@brown.edu/Shared drives/amos/ThesisResults/data/df_three.RData")
load("/Users/aokutse/Library/CloudStorage/GoogleDrive-amos_okutse@brown.edu/Shared drives/amos/ThesisResults/data/df_four.RData")

## load the list data files
load("/Users/aokutse/Library/CloudStorage/GoogleDrive-amos_okutse@brown.edu/Shared drives/amos/ThesisResults/data/dsets11.RData")
load("/Users/aokutse/Library/CloudStorage/GoogleDrive-amos_okutse@brown.edu/Shared drives/amos/ThesisResults/data/dsets22.RData")
load("/Users/aokutse/Library/CloudStorage/GoogleDrive-amos_okutse@brown.edu/Shared drives/amos/ThesisResults/data/dsets33.RData")
load("/Users/aokutse/Library/CloudStorage/GoogleDrive-amos_okutse@brown.edu/Shared drives/amos/ThesisResults/data/dsets44.RData")

## functions
bart_one <- function(df = NULL){
  # fit random forest model for all individuals
  bart_all <- parsnip::bart(
    mode = "regression") %>%
    set_engine("dbarts") %>% 
  fit(formula = y ~ A + x1 + x2 + x3 + x4, data = df)
## set A = 0 and generate predictions for everyone
  df_A0 <- df
  df_A0$A <- 0
  pred_A0 <- predict(bart_all, df_A0)
## set A = 1 and generate predictions for everyone
  df_A1 <- df
  df_A1$A <- 1
  pred_A1 <- predict(bart_all, df_A1)
## compute the ATE
  ATE_adjusted = mean(pred_A1$.pred - pred_A0$.pred)
## compute the bias
  bias_adjusted = ATE_adjusted - 50
## return the results as a data frame
  rslt = data.frame("ATE_adjusted" = ATE_adjusted, "bias_adjusted" = bias_adjusted)
  return(rslt)
}

bart_two <- function(df = NULL){
  ## filter the data to have only individuals with R = 1
  df = dplyr::filter(df, R == 1)
  # fit random forest model for all individuals
  bart_two <- parsnip::bart(
    mode = "regression") %>%
    set_engine("dbarts") %>% 
  fit(formula = y ~ A + x1 + x2 + x3 + x4, data = df)
## set A = 0 and generate predictions for everyone
  df_A0 <- df
  df_A0$A <- 0
  pred_A0 <- predict(bart_two, df_A0)
## set A = 1 and generate predictions for everyone
  df_A1 <- df
  df_A1$A <- 1
  pred_A1 <- predict(bart_two, df_A1)
## compute the ATE
  ATE_adjusted = mean(pred_A1$.pred - pred_A0$.pred)
## compute the bias
  bias_adjusted = ATE_adjusted - 50
## return the results as a data frame
  rslt = data.frame("ATE_adjusted" = ATE_adjusted, "bias_adjusted" = bias_adjusted)
  return(rslt)
}

bart_three <- function(df = NULL){
  # fit random forest model for all individuals with R=1
  bart_three <- parsnip::bart(
    mode = "regression") %>%
    set_engine("dbarts") %>% 
  fit(formula = y ~ A + x1 + x2 + x3 + x4, data = dplyr::filter(df, R == 1))
## set A = 0 and generate predictions for everyone
  df_A0 <- df
  df_A0$A <- 0
  pred_A0 <- predict(bart_three, df_A0)
## set A = 1 and generate predictions for everyone
  df_A1 <- df
  df_A1$A <- 1
  pred_A1 <- predict(bart_three, df_A1)
## compute the ATE
  ATE_adjusted = mean(pred_A1$.pred) - mean(pred_A0$.pred)
## compute the bias
  bias_adjusted = ATE_adjusted - 50
## return the results as a data frame
  rslt = data.frame("ATE_adjusted" = ATE_adjusted, "bias_adjusted" = bias_adjusted)
  return(rslt)
}
```

### FULL 

```{r}
cores <- parallel::detectCores()-1
doParallel::registerDoParallel(cores)
cl = parallel::makeCluster(cores)
pkgs = clusterEvalQ(cl, c(library(tidyverse), library(tidymodels), library(magrittr)))
parallel::clusterSetRNGStream(cl, 123)
## compute the estimates of the average treatment effect for each data set
  oneaa = parLapply(cl, dsets11, bart_one)
  onebb = parLapply(cl, dsets22, bart_one)
  onecc = parLapply(cl, dsets33, bart_one)
  onedd = parLapply(cl, dsets44, bart_one)
stopCluster(cl)
```


```{r}
# combine the results into a data frame
  oneaa <- oneaa %>% map_dfr(data.frame)
  onebb <- onebb %>% map_dfr(data.frame)
  onecc <- onecc %>% map_dfr(data.frame)
  onedd <- onedd %>% map_dfr(data.frame)
```

### OBSERVED

```{r}
cores <- parallel::detectCores()-1
doParallel::registerDoParallel(cores)
cl = parallel::makeCluster(cores)
pkgs = clusterEvalQ(cl, c(library(tidyverse), library(tidymodels), library(magrittr)))
parallel::clusterSetRNGStream(cl, 123)
## compute the estimates of the average treatment effect for each data set
  twoaa = parLapply(cl, dsets11, bart_two)
  twobb = parLapply(cl, dsets22, bart_two)
  twocc = parLapply(cl, dsets33, bart_two)
  twodd = parLapply(cl, dsets44, bart_two)
stopCluster(cl)
```

```{r}
# combine the results into a data frame
  twoaa <- twoaa %>% map_dfr(data.frame)
  twobb <- twobb %>% map_dfr(data.frame)
  twocc <- twocc %>% map_dfr(data.frame)
  twodd <- twodd %>% map_dfr(data.frame)
```

### OBSERVED MODIFIED

```{r}
cores <- parallel::detectCores()-1
doParallel::registerDoParallel(cores)
cl = parallel::makeCluster(cores)
pkgs = clusterEvalQ(cl, c(library(tidyverse), library(tidymodels), library(magrittr)))
parallel::clusterSetRNGStream(cl, 123)
## compute the estimated results across 1000 data frames
  threeaa = parLapply(cl, dsets11, bart_three)
  threebb = parLapply(cl, dsets22, bart_three)
  threecc = parLapply(cl, dsets33, bart_three)
  threedd = parLapply(cl, dsets44, bart_three)
stopCluster(cl)
```

```{r}
# combine the results into a data frame
  threeaa <- threeaa %>% map_dfr(data.frame)
  threebb <- threebb %>% map_dfr(data.frame)
  threecc <- threecc %>% map_dfr(data.frame)
  threedd <- threedd %>% map_dfr(data.frame)
```

### RESULTS B

```{r}
##------------------------------------------------------------------------------
## case 1 [n = 500, SD = 23]
##------------------------------------------------------------------------------
## full
full <- c(n = nrow(df_one), ate = mean(oneaa$ATE_adjusted), sd = sd(oneaa$ATE_adjusted), bias = mean(oneaa$bias_adjusted))
full
## observed
obs <- c(n = nrow(subset(df_one, R == 1)), ate = mean(twoaa$ATE_adjusted), sd = sd(twoaa$ATE_adjusted), bias = mean(twoaa$bias_adjusted))
obs
## observed modified
obs_m <- c(n = nrow(subset(df_one, R == 1)), ate = mean(threeaa$ATE_adjusted), sd = sd(threeaa$ATE_adjusted), bias = mean(threeaa$bias_adjusted))
obs_m


##------------------------------------------------------------------------------
## case 2 [n = 500, sd = 68]
##------------------------------------------------------------------------------
full2 <- c(n = nrow(df_two), ate = mean(onebb$ATE_adjusted), sd = sd(onebb$ATE_adjusted), bias = mean(onebb$bias_adjusted))
full2
## observed
obs2 <- c(n = nrow(subset(df_two, R == 1)), ate = mean(twobb$ATE_adjusted), sd = sd(twobb$ATE_adjusted), bias = mean(twobb$bias_adjusted))
obs2
## observed modified
obs_m2 <- c(n = nrow(subset(df_two, R == 1)), ate = mean(threebb$ATE_adjusted), sd = sd(threebb$ATE_adjusted), bias = mean(threebb$bias_adjusted))
obs_m2


##------------------------------------------------------------------------------
## case 3 [n = 2000, sd = 23]
##------------------------------------------------------------------------------
full3 <- c(n = nrow(df_three), ate = mean(onecc$ATE_adjusted), sd = sd(onecc$ATE_adjusted), bias = mean(onecc$bias_adjusted))
full3
## observed
obs3 <- c(n = nrow(subset(df_three, R == 1)), ate = mean(twocc$ATE_adjusted), sd = sd(twocc$ATE_adjusted), bias = mean(twocc$bias_adjusted))
obs3
## observed modified
obs_m3 <- c(n = nrow(subset(df_three, R == 1)), ate = mean(threecc$ATE_adjusted), sd = sd(threecc$ATE_adjusted), bias = mean(threecc$bias_adjusted))
obs_m3

##------------------------------------------------------------------------------
## case 4 [n = 2000, sd = 68]
##------------------------------------------------------------------------------
full4 <- c(n = nrow(df_four), ate = mean(onedd$ATE_adjusted), sd = sd(onedd$ATE_adjusted), bias = mean(onedd$bias_adjusted))
full4
## observed
obs4 <- c(n = nrow(subset(df_four, R == 1)), ate = mean(twodd$ATE_adjusted), sd = sd(twodd$ATE_adjusted), bias = mean(twodd$bias_adjusted))
obs4
## observed modified
obs_m4 <- c(n = nrow(subset(df_four, R == 1)), ate = mean(threedd$ATE_adjusted), sd = sd(threedd$ATE_adjusted), bias = mean(threedd$bias_adjusted))
obs_m4
```

### EXPORT RESULTS TO TABLE

```{r}
bart_model = bind_rows(list("n = 500, SD = 23" = full, "n = 500, SD = 23" = obs, "n = 500, SD = 23"= obs_m, "n = 500, SD = 68" = full2, "n = 500, SD = 68" = obs2, "n = 500, SD = 68" = obs_m2, "n = 2000, SD = 23" = full3, "n = 2000, SD = 23" = obs3, "n = 2000, SD = 23" = obs_m3, "n = 2000, SD = 68" = full4, "n = 2000, SD = 68"=  obs4, "n = 2000, SD = 68" = obs_m4), .id = "Data generating values") 
kable(bart_model, format = "latex", caption = "Version 2")


## the order of the rows starts with n = 500 
write.csv(bart_model, file = "/Users/aokutse/Library/CloudStorage/GoogleDrive-amos_okutse@brown.edu/Shared drives/amos/ThesisResults/[7]_bart/untuned_bartb.csv", row.names = FALSE)
```
